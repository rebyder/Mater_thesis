"""
Module that implements all the tools used by the Agents.

Tools:
    - CodeQLSastTool: created a CodeQL database and run SAST analysis 
    - ParseSarifTool: parses the SARIF reports into structured JSON fro LLM
    - WebSearchTool: performs web searches and returns the top 5 results
    - WriteQuerySubAgent: generates CodeQL queries for a given CWE
    - FinishTool: marks the completion of the CreatorAgent
    - FinishToolSuggestor: marks the completion of the SuggestorAgent
    - SuggestSubAgent: generates a detection plan for a new CodeQL query based on a CWE, snippet and existing queries.

Workflow:
    1. Source code is analyzed using CodeQLSastTool
    2. SARIF results are parsed by ParseSarifTool
    3. WebSearchTool can be invoked to gather context or insights
    4. SuggestSubAgent is used by SuggestorAgent to prepare suggestions for new queries
    5. CreatorAgent uses WriteQuerySubAgent and FinishTool to generate queries iteratively.

Args:
    Each tool class takes specific arguments as defined in their respective docstrings.
"""

import os
import json
import subprocess
import shutil
import sys
import requests
from bs4 import BeautifulSoup
import html2text

from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
from config import CODEQL_CLI, CODEQL_DB_PATH, QUERY_PACK, OUTPUT_QUERIES_PATH

def _run_command(command: List[str], step_name: str) -> str:
    """Execute shell command and handles errors.
    
    Args:
        command (List[str]): command to execute
        step_name (str): name of the step for logging
        
    Returns:
        str: standard output of the command

    Raises:
        Exception: if the command fails or CLI not found
    """

    print(f"\n--- {step_name} ---")
    try:
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            check=True,
            shell=False
        )
        print(f"Command executed: {' '.join(command)}")
        return result.stdout
    
    except subprocess.CalledProcessError as e:
        error_msg = f"ERROR in '{step_name}' step. Command failed: {' '.join(command)}. Stderr: {e.stderr}"
        print(error_msg)
        raise Exception(error_msg)
    
    except FileNotFoundError:
        error_msg = f"ERROR: The command '{CODEQL_CLI}' was not found. Ensure that CodeQL CLI is installed and in the PATH."
        print(error_msg)
        raise Exception(error_msg)


def _create_database(source_root: str):
    """
    Creator a CodeQL database from source code.

    Args:
        source_root (str): path to source code directory
    """

    if os.path.exists(CODEQL_DB_PATH):
        print(f"The database '{CODEQL_DB_PATH}' already exists. I delete and recreate it.")
        shutil.rmtree(CODEQL_DB_PATH)

    command = [
        CODEQL_CLI, "database", "create", CODEQL_DB_PATH,
        f"--language=python",
        f"--source-root={source_root}"
    ]
    _run_command(command, "Creation of Database CodeQL")


def _run_analysis(output_report_filepath: str) -> str:
    """
    Runs CodeQL analysis on a database and generates a SARIF report.
    
    Args:
        output_report_filepath (str): path to dave SARIF report

    Returns:
        str: path to generated SARIF report
    """
    
    command = [
        CODEQL_CLI, "database", "analyze", CODEQL_DB_PATH, QUERY_PACK,
        f"--format=sarifv2.1.0", 
        f"--output={output_report_filepath}"
    ]
    _run_command(command, "Execution of CodeQL Analysis")
    
    return output_report_filepath


class CodeQLSastTool(BaseModel):
    """
    Tool to execute the SAST analysis (Static Application Security Testing) using CodeQL CLI.
    
    Args:
        source_root (str): directory containig source code
        output_report_filepath (str): SARIF report output path
        query_path (Optional[str]): optional additional queries
    """
    source_root: str = Field(description="Path to the directory containing the source code to be analyzed.")
    output_report_filepath: str = Field(description="Path to the SARIF file where the report generated by CodeQL must be saved.")

    def run(self) -> str:
        """
        Runs the full CodeQL SAST cycle: database creation and analysis.

        Returns:
            str: confirmation massage with SARIF report path
        """

        if not os.path.isdir(self.source_root):
            raise Exception(f"Source root path '{self.source_root}' does not exist.")

        _create_database(self.source_root)
        
        sarif_path = _run_analysis(self.output_report_filepath)
        
        return f"CodeQL SAST analysis completed. SARIF report saved at: {sarif_path}"


class ParseSarifTool(BaseModel):
    """
    Tool to parse SARIF report and produced JSON results for LLM processing.

    Args:
        sarif_filepath (str): path to SARIF JSON file
    """

    sarif_filepath: str = Field(description="Path to the SARIF JSON file generated by CodeQL.")
    
    def run(self) -> str:
        """
        Reads the SARIF file and returns structured JSON.
        
        Returns:
            str: structured JSON string of results.
        """
        if not os.path.exists(self.sarif_filepath):
            raise Exception(f"ERROR: File '{self.sarif_filepath}' does not exist.")
        
        with open(self.sarif_filepath, 'r', encoding='utf-8') as f:
            sarif_data = json.load(f)
        
        structured_res: List[Dict[str, Any]] = []
        
        for runn in sarif_data.get('runs', []):
            tool_name = runn.get('tool', {}).get('driver', {}).get('name', 'CodeQL')

            for result in runn.get('results', []):
                rule_id = result.get('ruleId', 'unknown_rule')
                message = result.get('message', {}).get('text', 'No description')
                
                locations = [
                    {
                        'uri': loc.get('physicalLocation', {}).get('artifactLocation', {}).get('uri', 'unknown_file'),
                        'line': loc.get('physicalLocation', {}).get('region', {}).get('startLine')
                    }
                    for loc in result.get('locations', [])                 
                ]

                structured_res.append({
                    'tool': tool_name,
                    'rule_id': rule_id,
                    'message': message,
                    'locations': locations
                })
        
        if not structured_res:
            print("\n\nThe SARIF report is empty - there are no vulnerabilities in your dataset. The program will stop.")
            sys.exit(1)

        return json.dumps(structured_res, indent=2)


from ddgs import DDGS
"""
Exaple usage of DDGS:
results = DDGS().text('live free or die', region='wt-wt', safesearch='off', timelimit='y', max_results=10)

print(results)
[
    {
        "title": "News, sport, celebrities and gossip | The Sun",
        "href": "https://www.thesun.co.uk/",
        "body": "Get the latest news, exclusives, sport, celebrities, showbiz, politics, business and lifestyle from The Sun",
    }, ...
]
"""

class WebSearchTool(BaseModel):
    """
    Tool to perform web searches and return top 5 results.
    
    Args:
        query (str): search query string
    """

    query: str = Field(description="The search query (e.g., 'CodeQL python CWE-89 sink source names')")
   
    def run(self, llm=None) -> str:
        """
        Performs the search and returns results as JSON.
        
        Returns:
            str: JSON string of search results or error message
        """
        try:
            results = DDGS().text(f"site:codeql.github.com OR site:github.com {self.query}", max_results=3)
            h = html2text.HTML2Text() # in modo da preservare la sintassi di codeql
            h.ignore_links = True
            h.ignore_images = True

            final_context = []

            for res in results:
                url = res['href']
                try:
                    response = requests.get(url, timeout=5)
                    soup = BeautifulSoup(response.text, 'html.parser')

                    for junk in soup(['nav', 'footer', 'header', 'script', 'style']):
                        junk.decompose()
                    
                    texy_md = h.handle(str(soup))
                    
                    final_context.append(f"SOURCE: {url}\nCONTENT:\n{texy_md[:3000]}")
                except:
                    continue

            return "\n---\n".join(final_context)

        except Exception as e:
            return f"Errore: {str(e)}"



class WriteQuerySubAgent(BaseModel):
    """Tool to generate CodeQL query for a given CWE.
    
    Args:
        name_query: name of the new query generated.
        cwe: vulnerability for which generate the query.
        report: suggestor report from whhich take the suggestions.
    
    Methods:
        run(self, llm): Generates and writes the CodeQL query to disk.
    """

    name_query: str = Field(...)
    cwe: str = Field(...)
    report: str = Field(...)

    def run(self, llm) -> str:
        """Generates and writes the CodeQL query to disk."""

        prompt = f"""Role: you are an autonomous CodeQL Engineer.

        Context:
        Target CWE: {self.cwe}
        Analysis report/Detection plan: {self.report}

        Task: generate a valid '.ql' query for Python.

        Operational guidelines:
        - Modular achitecture: you MUST implement a query using the `DataFlow::ConfigSig` and `TaintTracking::Global<...>` pattern (the `TaintTracking::Configuration` doesn't work).
        - Import logic: never import individual classes or members (e.g., NO `import DataFlow::Node`). Always import the full library path:
            - import semmle.code.python.dataflow.new.DataFlow
            - import semmle.code.python.dataflow.new.TaintTracking
            - import semmle.code.python.dataflow.new.RemoteFlowSources
        - PathGraph requirements: since it is a `@kind path-problem` you MUST import `MyFlow::PathGraph` (where `MyFlow` is your instantiated globaln tracking module) in order to make the `select` clause work.
        
        Mandatory template to follow:
            To ensure compilation, follow this architectural skeleton:
            import python
            import semmle.code.python.dataflow.new.DataFlow
            import semmle.code.python.dataflow.new.TaintTracking
            import MyFlow::PathGraph

            module MyConfig implements DataFlow::ConfigSig {{
            predicate isSource(DataFlow::Node source) {{ 
                // Logic for sources (e.g., RemoteFlowSource)
            }}
            predicate isSink(DataFlow::Node sink) {{ 
                // Logic for sinks (e.g., calls to execute)
            }}
            }}

            module MyFlow = TaintTracking::Global<MyConfig>;

            from MyFlow::PathNode source, MyFlow::PathNode sink
            where MyFlow::flowPath(source, sink)
            select sink.getNode(), source, sink, "Message $@.", source.getNode(), "Source Label"
        
        Important rules:
        - you MUST innovate the queries, not copy the existing ones.
        - you MUST use ONLY CodeQL syntax.
        - the query must be compile-ready
        - all necessary imports must be resolved autonomously.
        - AST precision: use exact Python AST elements. If you are unsure how CodeQL models a specific Python construct (like a decorator or a function call), search for "CodeQL Python AST [element]".

        Output requirements:
        1. Clean code: the code block must contain ONLY valid, compilable CodeQL. No placeholdern like "anyMethod...".
        2. Integrated documentation: move your explanation inside the '.ql' file using :
            - a header comment block (with `/** ... */`) for the general logic.
            - inline comments (using `\\`) to explain spefici predicates ot sinks.
        3. Metadata first: start the file with the mandatory metadata (@kind, @id, @name).
        4. Do not include the header '```ql' in the first line of the query.

        Important: Innovate by targeting the specific patterns identified in the report, but ground your innovation in real CodeQL library capabilities.
        """
        
        try:
            response = llm.invoke(prompt)
            final_query = response.content if hasattr(response, 'content') else str(response)
        
            if not final_query:
                return "ERROR: The LLM returned an empty response."

            os.makedirs(OUTPUT_QUERIES_PATH, exist_ok=True)

            # Create the qlpack.yml which contains all the generated queries
            qlpack_path = os.path.join(OUTPUT_QUERIES_PATH, "qlpack.yml")
            if not os.path.exists(qlpack_path):
                with open(qlpack_path, "w") as f:
                    f.write("name: custom-python-queries\n")
                    f.write("version: 1.0.0\n")
                    f.write("dependencies:\n")
                    f.write("  codeql/python-all: '*'\n")
                    
            safe_filename = self.cwe.replace("-", "_") + ".ql"
            filepath = os.path.join(OUTPUT_QUERIES_PATH, safe_filename)

            with open(filepath, "w", encoding="utf-8") as f:
                f.write(final_query)

            try:
                print("Installing codeql pack dependencies to test the new queries.\n")
                subprocess.run(
                    ["codeql", "pack", "install", OUTPUT_QUERIES_PATH], 
                    capture_output=True, text=True, check=True
                )
            except subprocess.CalledProcessError as e:
                return f"Failed to install dependencies."

            result = subprocess.run(
                ["codeql", "query", "compile", "--check-only", filepath],
                capture_output=True, text=True
            )

            if result.returncode == 0:
                return f"SUCCESS: query validated and saved at {filepath}"
            else:
                return (f"ERROR: {result.stderr}\n"
                            "INSTRUCTION: Analyze the error carefully. Use WebSearchTool to find the specific CodeQL Python API for 'semmle.python.dataflow.new' that resolves this issue.")
        except Exception as e:
            return f"ERROR during query generation: {str(e)}"        

class FinishTool(BaseModel):
    """Tool to signal completion and generate query suite."""
    final_repo: str = Field(description="Final report message")


class FinishToolSuggestor(BaseModel):
    """Tool called by SuggestorAgent when work is complete."""
    final_report: str = Field(...)


class ExistingQuery(BaseModel):
    """Represents an existing CodeQL query for reference."""
    filename: str
    content: str


class SuggestSubAgent(BaseModel):
    """
    Sub-agent to generate a detection plan for a new CodeQL query. 
    
    Args:
       cwe (str): target CWE
       description (str): target CWE's description
       file (str): file containing the vulnerability
       existing_queries (Optional[List[ExistingQuery]]): list of locally existing queries 
       validation_audits: Analyzer's validation of the CodeQL
    """

    cwe: str = Field(...)
    description: str = Field(...)
    code_contexts: List[str] = Field(...)
    existing_queries: Optional[List[ExistingQuery]] = Field(default_factory=list)
    validation_audit: List[str] = Field(default_factory=list)

    def run(self, llm) -> str:
        """
        Generates suggetions a detection plan for a new CodeQL query.

        Returns: 
            str: LLM-generated detection plan.
        """

        existing_queries = "\n\n".join([q.content for q in self.existing_queries])  
        combined_codes = "\n\n".join([f"Instances {i+1}\n:{code}" for i, code in enumerate(self.code_contexts)])     

        if self.validation_audit:
            combined_audit= "\n\n".join([f"--- Audit {i+1} ---\n{audit}" for i, audit in enumerate(self.validation_audit)])
        else:
            combined_audit = "No specific audit provided. Use general best practices."

        prompt = f"""Role: You are a CodeQL Expert providing technical specifications.
        
        Context for {self.cwe}:
        - Description of the cwe: {self.description}
        - Code context: {combined_codes}
        - Validation audits: {combined_audit}

        Instructions: generate a "Technical AST Detection Plan" with technical instructions about how to write a new, enhanced and predictive CodeQL query.
        
        Your "Technical AST Detection Plan" must:
        1. Deconstruct the Taint-Flow: map the path from untrusted entry points to dangerous execution sinks.
        2. Modern API intelligence: don't limit yourself to the code provided. Don't just look at the provided code. Suggest sinks for modern Python database libraries (SQLAlchemy, Django ORM, asyncpg) that fit this CWE.
           Suggest potential sanitizers (e.g., "calls to `int()` or `float()`", "use of prepared statements"). If you are unsure about that you must call the `WebSearchTool`.
        3. Precision mapping: clearly distinguish between AST elements (Attribute vs Call) to avoid the compilation errors seen in previous iterations
        4. Use structural AST details:
            - specify if a node is a `Call` (e.g., `execute()`), a `Name` (e.g., `query`) or an `Attribute` (e.g., `request.form`)
        5. Modeling Pattern: Explicitly recommend a Modular Configuration structure (Source, Sink, and Sanitizer predicates together). Suggest to implements a  'ConfigSig' to allow the global tracking of data across multiple function boundaries.

        Important rule:
        Do NOT use CodeQL syntax. Use Python syntax (e.g., "method arguments", "dictionary keys") that can be mapped to AST nodes.
        """
        #Taint-FLow = flusso di contaminazione

        response = llm.invoke(prompt)
        return response.content
     